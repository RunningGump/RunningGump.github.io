<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>体验活动的生命周期</title>
      <link href="/2018/11/16/%E4%BD%93%E9%AA%8C%E6%B4%BB%E5%8A%A8%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"/>
      <url>/2018/11/16/%E4%BD%93%E9%AA%8C%E6%B4%BB%E5%8A%A8%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</url>
      
        <content type="html"><![CDATA[<p>在动手实现这小实验之前，最好先去了解活动生命周期的4种状态以及Activity类中定义的7个回调方法。</p><h2 id="新建一个项目"><a href="#新建一个项目" class="headerlink" title="新建一个项目"></a>新建一个项目</h2><ol><li>新建一个名为ActivityLifeCycleTest的项目，点击Next。</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116085352727.png" alt="image-20181116085352727"></p><ol><li>保持默认选项，再点击Next。</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116085453492.png" alt="image-20181116085453492"></p><ol><li>选择一个空项目，让Android帮我们自动创建活动和布局。</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116085840469.png" alt="image-20181116085840469"></p><ol><li>活动名和布局名都是用默认值。</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116090722988.png" alt="image-20181116090722988"></p><p>到此为止，我们的主活动就创建完毕了。</p><h2 id="创建两个子活动"><a href="#创建两个子活动" class="headerlink" title="创建两个子活动"></a>创建两个子活动</h2><p>创建两个子活动，分别名为NormalActivity和DialogActivity。</p><ol><li>新建NormalActivity子活动。</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116091658116.png" alt="image-20181116091658116"></p><p>布局起名为activity_normal，点击Finish。</p><p><img src="/2018/11/16/体验活动的生命周期/image-20181116091844066.png" alt="image-20181116091844066"></p><ol><li>新建DialogActivity子活动，布局起名为activity_dialog，创建方法同上。</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116092419983.png" alt="image-20181116092419983"></p><p>到此，两个子活动创建完毕。</p><h2 id="编写活动的布局文件"><a href="#编写活动的布局文件" class="headerlink" title="编写活动的布局文件"></a>编写活动的布局文件</h2><ol><li>编写activity_normal.xml文件，将里面的代码替换成如下内容：</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">LinearLayout</span> <span class="attr">xmlns:android</span>=<span class="string">"http://schemas.android.com/apk/res/android"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_height</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:orientation</span>=<span class="string">"vertical"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">TextView</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_height</span>=<span class="string">"wrap_content"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:text</span>=<span class="string">"This is a normal activity"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">LinearLayout</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这个布局中我们使用了一个TextView，用于显示一行文字。</p><ol><li>编辑activity_dialog.xml文件，将里面的内容代码替换成如下内容：</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">LinearLayout</span> <span class="attr">xmlns:android</span>=<span class="string">"http://schemas.android.com/apk/res/android"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_height</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:orientation</span>=<span class="string">"vertical"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">TextView</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_height</span>=<span class="string">"wrap_content"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:text</span>=<span class="string">"This is a dialog activity"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">LinearLayout</span>&gt;</span></span><br></pre></td></tr></table></figure><ol><li>修改AndroidManifest.xml文件的<code>&lt;activity&gt;</code>标签的配置，将DialogActivity活动指定为对话框式的主题。</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">activity</span> <span class="attr">android:name</span>=<span class="string">".MainActivity"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">intent-filter</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">action</span> <span class="attr">android:name</span>=<span class="string">"android.intent.action.MAIN"</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">category</span> <span class="attr">android:name</span>=<span class="string">"android.intent.category.LAUNCHER"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">intent-filter</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">activity</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">activity</span> <span class="attr">android:name</span>=<span class="string">".NormalActivit"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">activity</span> <span class="attr">android:name</span>=<span class="string">".DialogActivity"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:theme</span>=<span class="string">"@style/Theme.AppCompat.Dialog"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">activity</span>&gt;</span></span><br></pre></td></tr></table></figure><ol><li>修改activity_main.xml文件，重新定制主活动的布局，替换为如下内容：</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">LinearLayout</span> <span class="attr">xmlns:android</span>=<span class="string">"http://schemas.android.com/apk/res/android"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_height</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:orientation</span>=<span class="string">"vertical"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Button</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:id</span>=<span class="string">"@+id/start_normal_activity"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_height</span>=<span class="string">"wrap_content"</span> </span></span><br><span class="line"><span class="tag"><span class="attr">android:text</span>=<span class="string">"Start NormalActivity"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">Button</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:id</span>=<span class="string">"@+id/start_dialog_activity"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:layout_height</span>=<span class="string">"wrap_content"</span></span></span><br><span class="line"><span class="tag"><span class="attr">android:text</span>=<span class="string">"Start DialogActivity"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">LinearLayout</span>&gt;</span></span><br></pre></td></tr></table></figure><p>我们在LineaLayout中加入了两个按钮，一个用于启动NormalActivity，一个用于启动DialogActivity。</p><h2 id="修改MainActivity"><a href="#修改MainActivity" class="headerlink" title="修改MainActivity"></a>修改MainActivity</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.edu.pku.gengzehao.activitylifecycletest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> android.content.Intent;</span><br><span class="line"><span class="keyword">import</span> android.support.v7.app.AppCompatActivity;</span><br><span class="line"><span class="keyword">import</span> android.os.Bundle;</span><br><span class="line"><span class="keyword">import</span> android.util.Log;</span><br><span class="line"><span class="keyword">import</span> android.view.View;</span><br><span class="line"><span class="keyword">import</span> android.widget.Button;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainActivity</span> <span class="keyword">extends</span> <span class="title">AppCompatActivity</span> <span class="keyword">implements</span> <span class="title">View</span>.<span class="title">OnClickListener</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TAG = <span class="string">"MainActivity"</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onCreate</span><span class="params">(Bundle savedInstanceState)</span> </span>&#123;</span><br><span class="line"><span class="keyword">super</span>.onCreate(savedInstanceState);</span><br><span class="line">Log.d(TAG, <span class="string">"onCreate"</span>);</span><br><span class="line">setContentView(R.layout.activity_main);</span><br><span class="line"></span><br><span class="line">Button startNormalActivity = (Button) findViewById(R.id.start_normal_activity);</span><br><span class="line">startNormalActivity.setOnClickListener(<span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">Button startDialogActivity = (Button) findViewById(R.id.start_dialog_activity);</span><br><span class="line">startDialogActivity.setOnClickListener(<span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onClick</span><span class="params">(View v)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (v.getId() == R.id.start_normal_activity)&#123;</span><br><span class="line">Intent intent = <span class="keyword">new</span> Intent(MainActivity.<span class="keyword">this</span>, NormalActivit.class);</span><br><span class="line">startActivity(intent);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (v.getId() == R.id.start_dialog_activity)&#123;</span><br><span class="line">Intent intent = <span class="keyword">new</span> Intent(MainActivity.<span class="keyword">this</span>, DialogActivity.class);</span><br><span class="line">startActivity(intent);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onStart</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">super</span>.onStart();</span><br><span class="line">Log.d(TAG, <span class="string">"onStart"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onResume</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">super</span>.onResume();</span><br><span class="line">Log.d(TAG, <span class="string">"onResume"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onPause</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">super</span>.onPause();</span><br><span class="line">Log.d(TAG, <span class="string">"onPause"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onStop</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">super</span>.onStop();</span><br><span class="line">Log.d(TAG, <span class="string">"onStop"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onDestroy</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">super</span>.onDestroy();</span><br><span class="line">Log.d(TAG, <span class="string">"onDestroy"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onRestart</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">super</span>.onRestart();</span><br><span class="line">Log.d(TAG, <span class="string">"onRestart"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再onCreate方法中，我们我们分别为两个按钮注册了点击事件，点击第一个按钮会启动NoramalActivity。点击第二个按钮会启动DialogActivity。然后再Activity的7个回调方法中分别打印了回调方法的名字，这样就可以通过观察日志的方式来更直观的理解活动的生命周期。</p><h2 id="运行程序"><a href="#运行程序" class="headerlink" title="运行程序"></a>运行程序</h2><ol><li>启动程序：</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116105015976.png" alt="image-20181116105015976"></p><p>启动程序时，logcat中的日志信息如下图，可以看到当MainActivity第一被创建时会一次执行onCreate()、onStart()、onResume()方法。</p><p><img src="/2018/11/16/体验活动的生命周期/image-20181116105139134.png" alt="image-20181116105139134"></p><ol><li>点击一个按钮，启动NormalActivity。</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116105613231.png" alt="image-20181116105613231"></p><p>打开NormalActivity时的打印日志：</p><p><img src="/2018/11/16/体验活动的生命周期/image-20181116105804164.png" alt="image-20181116105804164"></p><p>由于NormalActivity已经把MainActivity完全遮挡，因此onPause()和onStop()方法都会得到执行。</p><ol><li>按下Back键返回MainActivity的打印日志信息如下。</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116110125194.png" alt="image-20181116110125194"></p><p>由于之前的MainActivity已经进入了停止状态，所以onRestart() 方法才会的到执行，之后又会依次执行onSrart()  和onResume()方法。值的注意的是，此时onCreate()方法不会执行。</p><ol><li>再点击第二个按钮，启动DialogActivity。</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116120841989.png" alt="image-20181116120841989"></p><p>打开DialogActivity时的打印日志：</p><p><img src="/2018/11/16/体验活动的生命周期/image-20181116120948371.png" alt="image-20181116120948371"></p><p>只有onPause()方法得到了执行，onStop()方法并没有执行。这是因为DialogActivity并没有完全遮挡住MainActivity，此时MainActivity只是进入了暂停状态，并没有进入停止状态。</p><ol><li>按下Back键再次返回MainActivity时的打印日志为：</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116121404897.png" alt="image-20181116121404897"></p><p>可以看到，只有onResume ()方法得到了执行。</p><ol><li>最后，在MainActivity按下Back键退出程序，打印日志如下：</li></ol><p><img src="/2018/11/16/体验活动的生命周期/image-20181116121609853.png" alt="image-20181116121609853"></p><p>依次会执行onPause()、onStop()、 onDestroy()方法，最终销毁MainActivity。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>《第一行代码 Android》郭霖  </p>]]></content>
      
      
      <categories>
          
          <category> Android </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>Hexo博客迁移到一台新电脑</title>
      <link href="/2018/10/29/Hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E5%88%B0%E5%8F%A6%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91/"/>
      <url>/2018/10/29/Hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E5%88%B0%E5%8F%A6%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>由于10月份换了一台Macbook Pro，导致自己搭建的Hexo博客一直停滞了。我想人做事一定要善始善终，不要忘记当初搭建Hexo博客的初心。于是乎，就有了这一篇文章。</p><h1 id="迁移思路"><a href="#迁移思路" class="headerlink" title="迁移思路"></a>迁移思路</h1><p>在已经推送到Github上的Hexo静态网页创建一个分支，利用这个分支来管理自己的Hexo环境文件。</p><h1 id="迁移步骤"><a href="#迁移步骤" class="headerlink" title="迁移步骤"></a>迁移步骤</h1><h2 id="1-在旧机器上克隆Github上面生成的静态文件到本地"><a href="#1-在旧机器上克隆Github上面生成的静态文件到本地" class="headerlink" title="1.在旧机器上克隆Github上面生成的静态文件到本地"></a>1.在旧机器上克隆Github上面生成的静态文件到本地</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/username/username.github.io.git</span><br></pre></td></tr></table></figure><h2 id="2-针对克隆到本地的文件中，将除去-git文件的所有文件都删除"><a href="#2-针对克隆到本地的文件中，将除去-git文件的所有文件都删除" class="headerlink" title="2.针对克隆到本地的文件中，将除去.git文件的所有文件都删除"></a>2.针对克隆到本地的文件中，将除去<code>.git</code>文件的所有文件都删除</h2><h2 id="3-将旧机器中所有文件-gitignore文件中包含的文件除外）拷贝到我们克隆下来的文件内"><a href="#3-将旧机器中所有文件-gitignore文件中包含的文件除外）拷贝到我们克隆下来的文件内" class="headerlink" title="3.将旧机器中所有文件(.gitignore文件中包含的文件除外）拷贝到我们克隆下来的文件内"></a>3.将旧机器中所有文件(<code>.gitignore</code>文件中包含的文件除外）拷贝到我们克隆下来的文件内</h2><h2 id="4-创建并切换到一个叫hexo的分支"><a href="#4-创建并切换到一个叫hexo的分支" class="headerlink" title="4. 创建并切换到一个叫hexo的分支"></a>4. 创建并切换到一个叫hexo的分支</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b hexo</span><br></pre></td></tr></table></figure><h2 id="5-提交复制过来的文件到暂存取"><a href="#5-提交复制过来的文件到暂存取" class="headerlink" title="5. 提交复制过来的文件到暂存取"></a>5. 提交复制过来的文件到暂存取</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add -A</span><br></pre></td></tr></table></figure><h2 id="6-提交"><a href="#6-提交" class="headerlink" title="6.提交"></a>6.提交</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m <span class="string">"ceate a new branch file"</span></span><br></pre></td></tr></table></figure><h2 id="7-推送到Github"><a href="#7-推送到Github" class="headerlink" title="7.推送到Github"></a>7.推送到Github</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push --<span class="built_in">set</span>-upstream origin hexo</span><br></pre></td></tr></table></figure><p>这个时候hexo分支已经创建完毕，接下来，我们在新电脑上搭建环境。</p><h2 id="8-新电脑配置环境"><a href="#8-新电脑配置环境" class="headerlink" title="8.新电脑配置环境"></a>8.新电脑配置环境</h2><p>安装node.js，根据自己电脑系统自行百度安装。</p><p>安装git，git相关教程推荐<a href="https://link.jianshu.com/?t=https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">廖雪峰老师的git教程</a>。</p><p>安装hexo： <code>npm install -g hexo-cli</code></p><h2 id="9-clone远程仓库到本地"><a href="#9-clone远程仓库到本地" class="headerlink" title="9.clone远程仓库到本地"></a>9.clone远程仓库到本地</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> -b hexo https://github.com/username/username.github.io.git</span><br></pre></td></tr></table></figure><h2 id="10-根据package-json安装依赖"><a href="#10-根据package-json安装依赖" class="headerlink" title="10.根据package.json安装依赖"></a>10.根据<code>package.json</code>安装依赖</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install *** --save</span><br></pre></td></tr></table></figure><p>将<code>***</code>替换为<code>package.json</code>文件内的依赖包</p><h2 id="11-开始写文章"><a href="#11-开始写文章" class="headerlink" title="11.开始写文章"></a>11.开始写文章</h2><p>我们现在可以通过<code>hexo n &quot;文章标题&quot;</code> 创建一篇文章了！</p><h2 id="12-提交hexo环境文件"><a href="#12-提交hexo环境文件" class="headerlink" title="12.  提交hexo环境文件"></a>12.  提交hexo环境文件</h2><p><code>git add .</code></p><p><code>git commit -m &quot;some description&quot;</code></p><p><code>git push origin hexo</code></p><h2 id="13-发布文章"><a href="#13-发布文章" class="headerlink" title="13.发布文章"></a>13.发布文章</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure><p>到这里，我们的Hexo博客就迁移完毕了！！以后再写文章时，只需要重复步骤11、12、13就ok啦！！</p>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo迁移 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>基于Scrapy框架的CrawlSpider类爬取当当全网商品信息</title>
      <link href="/2018/09/01/%E5%9F%BA%E4%BA%8EScrapy%E6%A1%86%E6%9E%B6%E7%9A%84CrawlSpider%E7%B1%BB%E7%88%AC%E5%8F%96%E5%BD%93%E5%BD%93%E5%85%A8%E7%BD%91%E5%95%86%E5%93%81%E4%BF%A1%E6%81%AF/"/>
      <url>/2018/09/01/%E5%9F%BA%E4%BA%8EScrapy%E6%A1%86%E6%9E%B6%E7%9A%84CrawlSpider%E7%B1%BB%E7%88%AC%E5%8F%96%E5%BD%93%E5%BD%93%E5%85%A8%E7%BD%91%E5%95%86%E5%93%81%E4%BF%A1%E6%81%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本项目通过使用Scrapy框架的CrawlSpider类，对当当全网商品信息进行爬取并将信息保存至mysql数据库，当当网反爬措施是对IP访问频率的限制，所以本项目使用了中间件<code>scrapy-rotating-proxies</code>来管控IP代理池，有关代理ip的爬取请见我的另一篇博文。</p><p>CrawlSpider是Spider的派生类，Spider类的设计原则是只爬取start_url列表中的网页，而CrawlSpider类通过定义一些规则(rule)来跟进所爬取网页中的link，从爬取的网页中获取link并继续爬取。</p><p>Github地址: <a href="https://github.com/RunningGump/crawl_dangdang" target="_blank" rel="noopener">https://github.com/RunningGump/crawl_dangdang</a></p><h1 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h1><ol><li>scrapy 1.5.0</li><li>python3.6</li><li>mysql 5.7</li><li>pymysql 库</li><li>scrapy-rotating-proxies 库</li><li>fake-useragent 库</li></ol><h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><p>首先，我们需要创建一个Scrapy项目，在shell中使用<code>scrapy startproject</code>命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy startproject Dangdang</span><br><span class="line">New Scrapy project <span class="string">'Dangdang'</span>, using template directory <span class="string">'/usr/local/lib/python3.6/dist-packages/scrapy/templates/project'</span>, created <span class="keyword">in</span>:</span><br><span class="line">    /home/geng/Dangdang</span><br><span class="line"></span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> Dangdang</span><br><span class="line">    scrapy genspider example example.com</span><br></pre></td></tr></table></figure><p>创建好一个名为<code>Dangdang</code>的项目后，接下来，你进入新建的项目目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> Dangdang</span><br></pre></td></tr></table></figure><p>然后,使用<code>scrapy genspider -t &lt;template&gt; &lt;name&gt; &lt;domain&gt;</code>创建一个spider：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy genspider -t crawl dd dangdang.com</span><br><span class="line">Created spider <span class="string">'dd'</span> using template <span class="string">'crawl'</span> <span class="keyword">in</span> module:</span><br><span class="line">  Dangdang.spiders.dd</span><br></pre></td></tr></table></figure><p>此时，你通过<code>cd ..</code>返回上级目录，使用<code>tree</code>命令查看项目目录下的文件，显示如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ..</span><br><span class="line">$ tree Dangdang/</span><br><span class="line">Dangdang/</span><br><span class="line">├── Dangdang</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── __pycache__</span><br><span class="line">│   │   ├── __init__.cpython-36.pyc</span><br><span class="line">│   │   └── settings.cpython-36.pyc</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       ├── dd.py</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── __pycache__</span><br><span class="line">│           └── __init__.cpython-36.pyc</span><br><span class="line">└── scrapy.cfg</span><br><span class="line"></span><br><span class="line">4 directories, 11 files</span><br></pre></td></tr></table></figure><p>到此为止，我们的项目就创建成功了。</p><h1 id="rules"><a href="#rules" class="headerlink" title="rules"></a>rules</h1><p>在rules中包含一个或多个Rule对象，每个Rule对爬取网站的动作设置了爬取规则。</p><p> <strong>参数介绍：</strong></p><p><code>link_extractor</code>：是一个Link Extractor对象，用于定义需要提取的链接。</p><p><code>callback</code>： 回调函数，对link_extractor获得的链接进行处理与解析。</p><p><strong>注意事项：</strong>当编写爬虫规则时，避免使用parse作为回调函数。由于CrawlSpider使用parse方法来实现其逻辑，如果覆盖了 parse方法，crawl spider将会运行失败。</p><p><code>follow</code>：是一个布尔(boolean)值，指定了根据规则从response提取的链接是否需要跟进。 如果callback为None，follow 默认设置为True ，否则默认为False</p><p><code>process_links</code>：指定该spider中哪个的函数将会被调用，从link_extractor中获取到链接列表时将会调用该函数。该方法主要用来过滤链接。          </p><p><code>process_request</code>：指定该spider中哪个的函数将会被调用， 该规则提取到每个request时都会调用该函数。 (用来过滤request)</p><h1 id="LinkExtrator"><a href="#LinkExtrator" class="headerlink" title="LinkExtrator"></a>LinkExtrator</h1><p><strong>参数介绍：</strong></p><p><code>allow</code>：满足括号中“正则表达式”的值会被提取，如果为空，则全部匹配。</p><p><code>deny</code>：与这个正则表达式(或正则表达式列表)匹配的URL不提取。</p><p><code>allow_domains</code>：会被提取的链接的域名。</p><p><code>deny_domains</code>：不会被提取链接的域名。</p><p><code>restrict_xpaths</code>：使用Xpath表达式与allow共同作用提取出同时符合对应Xpath表达式和正则表达式的链接；</p><h1 id="项目代码"><a href="#项目代码" class="headerlink" title="项目代码"></a>项目代码</h1><h2 id="编写item-py文件"><a href="#编写item-py文件" class="headerlink" title="编写item.py文件"></a>编写item.py文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DangdangItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    category = scrapy.Field()  <span class="comment"># 商品类别</span></span><br><span class="line">    title = scrapy.Field()    <span class="comment"># 商品名称</span></span><br><span class="line">    link = scrapy.Field()    <span class="comment"># 商品链接</span></span><br><span class="line">    price = scrapy.Field()   <span class="comment"># 商品价格</span></span><br><span class="line">    comment = scrapy.Field()  <span class="comment"># 商品评论数</span></span><br><span class="line">    rate = scrapy.Field()    <span class="comment"># 商品的好评率</span></span><br><span class="line">    source = scrapy.Field()      <span class="comment"># 商品的来源地</span></span><br><span class="line">    detail = scrapy.Field()   <span class="comment"># 商品详情</span></span><br><span class="line">    img_link = scrapy.Field() <span class="comment"># 商品图片链接</span></span><br></pre></td></tr></table></figure><h2 id="编写pipeline-py文件"><a href="#编写pipeline-py文件" class="headerlink" title="编写pipeline.py文件"></a>编写pipeline.py文件</h2><p>需提前创建好数据库，本项目创建的数据库名字为<code>dd</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">from</span> scrapy.conf <span class="keyword">import</span> settings</span><br><span class="line"></span><br><span class="line"><span class="comment">## pipeline默认是不开启的，需在settings.py中开启</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DangdangPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="comment">##建立数据库连接</span></span><br><span class="line">        conn = pymysql.connect(host=<span class="string">"localhost"</span>,user=<span class="string">"root"</span>,passwd=<span class="string">'yourpasswd'</span>,db=<span class="string">"dd"</span>,use_unicode=<span class="keyword">True</span>, charset=<span class="string">"utf8"</span>)</span><br><span class="line">        cur = conn.cursor()             <span class="comment"># 用来获得python执行Mysql命令的方法,也就是我们所说的操作游标</span></span><br><span class="line">        print(<span class="string">"mysql connect success"</span>)  <span class="comment"># 测试语句，这在程序执行时非常有效的理解程序是否执行到这一步</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            category = item[<span class="string">"category"</span>]</span><br><span class="line">            title = item[<span class="string">"title"</span>]</span><br><span class="line">            <span class="keyword">if</span> len(title)&gt;<span class="number">40</span>:</span><br><span class="line">                title = title[<span class="number">0</span>:<span class="number">40</span>] + <span class="string">'...'</span></span><br><span class="line">            link = item[<span class="string">"link"</span>]</span><br><span class="line">            img_link = item[<span class="string">'img_link'</span>]</span><br><span class="line">            price = item[<span class="string">"price"</span>]</span><br><span class="line">            comment = item[<span class="string">"comment"</span>]</span><br><span class="line">            rate = item[<span class="string">"rate"</span>]</span><br><span class="line">            source = item[<span class="string">"source"</span>]</span><br><span class="line">            detail = item[<span class="string">"detail"</span>]</span><br><span class="line"></span><br><span class="line">            sql = <span class="string">"INSERT INTO goods(category,title,price,comment,rate,source,detail,link,img_link) VALUES ('%s','%s','%s','%s','%s','%s','%s','%s','%s')"</span> % (category,title,price,comment,rate,source,detail,link,img_link)</span><br><span class="line">            print(sql)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> err:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            cur.execute(sql)         <span class="comment"># 真正执行MySQL语句，即查询TABLE_PARAMS表的数据</span></span><br><span class="line">            print(<span class="string">"insert success"</span>)  <span class="comment"># 测试语句</span></span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> err:</span><br><span class="line">            print(err)</span><br><span class="line">            conn.rollback() <span class="comment">#事务回滚,为了保证数据的有效性将数据恢复到本次操作之前的状态.有时候会存在一个事务包含多个操作，而多个操作又都有顺序，顺序执行操作时，有一个执行失败，则之前操作成功的也会回滚，即未操作的状态</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conn.commit()   <span class="comment">#当没有发生异常时，提交事务，避免出现一些不必要的错误</span></span><br><span class="line">            </span><br><span class="line">        conn.close()  <span class="comment">#关闭连接</span></span><br><span class="line">        <span class="keyword">return</span> item   <span class="comment">#框架要求返回一个item对象</span></span><br></pre></td></tr></table></figure><h2 id="编写middlewares-py"><a href="#编写middlewares-py" class="headerlink" title="编写middlewares.py"></a>编写middlewares.py</h2><p>本项目添加了<code>RandomUserAgentMiddleWare</code>中间件，用来随机更换UserAgent。在<code>middlewares.py</code>文件的最后面添加如下中间件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomUserAgentMiddleWare</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    随机更换User-Agent</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,crawler)</span>:</span></span><br><span class="line">        super(RandomUserAgentMiddleWare, self).__init__()</span><br><span class="line">        self.ua = UserAgent()</span><br><span class="line">        self.ua_type = crawler.settings.get(<span class="string">"RANDOM_UA_TYPE"</span>, <span class="string">"random"</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cls(crawler)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">get_ua_type</span><span class="params">()</span>:</span></span><br><span class="line">            <span class="keyword">return</span> getattr(self.ua, self.ua_type)   <span class="comment"># 取对象 ua 的 ua_type 的这个属性, 相当于 self.ua.self.ua_type</span></span><br><span class="line"></span><br><span class="line">        request.headers.setdefault(<span class="string">'User-Agent'</span>, get_ua_type())</span><br></pre></td></tr></table></figure><h2 id="修改settings-py-文件"><a href="#修改settings-py-文件" class="headerlink" title="修改settings.py 文件"></a>修改settings.py 文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">BOT_NAME = <span class="string">'Dangdang'</span></span><br><span class="line"></span><br><span class="line">SPIDER_MODULES = [<span class="string">'Dangdang.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'Dangdang.spiders'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不遵循robots协议</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载延迟设置为0，提高爬取速度</span></span><br><span class="line">DOWNLOAD_DELAY = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#禁用Cookie(默认情况下启用)</span></span><br><span class="line">COOKIES_ENABLED = <span class="keyword">False</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用所需要的下载中间件</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'rotating_proxies.middlewares.RotatingProxyMiddleware'</span>: <span class="number">610</span>,</span><br><span class="line">    <span class="string">'rotating_proxies.middlewares.BanDetectionMiddleware'</span>: <span class="number">620</span>,</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span>: <span class="keyword">None</span>,</span><br><span class="line">    <span class="string">'Dangdang.middlewares.RandomUserAgentMiddleWare'</span>: <span class="number">400</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 代理IP文件路径,此处需改为你自己的路径</span></span><br><span class="line">ROTATING_PROXY_LIST_PATH = <span class="string">'/home/geng/Projects/Dangdang/proxy.txt'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机更换UserAgent </span></span><br><span class="line">RANDOM_UA_TYPE = <span class="string">"random"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启pipeline</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'Dangdang.pipelines.DangdangPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="spider文件-dd-py-编写"><a href="#spider文件-dd-py-编写" class="headerlink" title="spider文件(dd.py)编写"></a>spider文件(dd.py)编写</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">from</span> Dangdang.items <span class="keyword">import</span> DangdangItem</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DdSpider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'dd'</span></span><br><span class="line">    allowed_domains = [<span class="string">'dangdang.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://category.dangdang.com/'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分析网页链接，编写rules规则,提取商品详情页的链接</span></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r'/cp\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.html$|/pg\d+-cp\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.html$'</span>, deny=<span class="string">r'/cp98.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.html'</span>),</span><br><span class="line">             follow=<span class="keyword">True</span>),</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r'/cid\d+.html$|/pg\d+-cid\d+.html$'</span>, deny=<span class="string">r'/cp98.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.html'</span>),</span><br><span class="line">             follow=<span class="keyword">True</span>),</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r'product.dangdang.com/\d+.html$'</span>, restrict_xpaths=(<span class="string">"//p[@class='name']/a"</span>)),</span><br><span class="line">             callback=<span class="string">'parse_item'</span>,</span><br><span class="line">             follow=<span class="keyword">False</span>),      <span class="comment"># allow与restrict_xpath配合使用,效果很好,可以更精准筛选链接.</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析商品详情页面</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = DangdangItem()  <span class="comment"># 实例化item</span></span><br><span class="line">        item[<span class="string">"category"</span>] = response.xpath(<span class="string">'//*[@id="breadcrumb"]/a[1]/b/text()'</span>).extract_first()+<span class="string">'&gt;'</span>+response.xpath(<span class="string">'//*[@id="breadcrumb"]/a[2]/text()'</span>).extract_first()+<span class="string">'&gt;'</span>+response.xpath(<span class="string">'//*[@id="breadcrumb"]/a[3]/text()'</span>).extract_first()</span><br><span class="line">        item[<span class="string">"title"</span>] = response.xpath(<span class="string">"//*[@id='product_info']/div[1]/h1/@title"</span>).extract_first()</span><br><span class="line">        item[<span class="string">"detail"</span>] = json.dumps(response.xpath(<span class="string">"//*[@id='detail_describe']/ul//li/text()"</span>).extract(),ensure_ascii=<span class="keyword">False</span>)</span><br><span class="line">        item[<span class="string">"link"</span>] = response.url</span><br><span class="line">        item[<span class="string">"img_link"</span>] =json.dumps(response.xpath(<span class="string">"//div[@class='img_list']/ul//li/a/@data-imghref"</span>).extract())</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            item[<span class="string">"price"</span>] = response.xpath(<span class="string">"//*[@id='dd-price']/text()"</span>).extract()[<span class="number">1</span>].strip()</span><br><span class="line">        <span class="keyword">except</span> IndexError <span class="keyword">as</span> e:</span><br><span class="line">            item[<span class="string">"price"</span>] = response.xpath(<span class="string">"//*[@id='dd-price']/text()"</span>).extract()[<span class="number">0</span>].strip()</span><br><span class="line">            item[<span class="string">"comment"</span>] = response.xpath(<span class="string">"//*[@id='comm_num_down']/text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            item[<span class="string">"source"</span>] = response.xpath(<span class="string">"//*[@id='shop-geo-name']/text()"</span>).extract()[<span class="number">0</span>].replace(<span class="string">'\xa0至'</span>,<span class="string">''</span>)</span><br><span class="line">        <span class="keyword">except</span> IndexError <span class="keyword">as</span> e:</span><br><span class="line">            item[<span class="string">"source"</span>] = <span class="string">'当当自营'</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 通过抓包分析,提取商品的好评率</span></span><br><span class="line">        goodsid = re.compile(<span class="string">'\/(\d+).html'</span>).findall(response.url)[<span class="number">0</span>]  <span class="comment"># 提取url中的商品id</span></span><br><span class="line">        <span class="comment"># 提取详情页源码中的categoryPath</span></span><br><span class="line">        script = response.xpath(<span class="string">"/html/body/script[1]/text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        categoryPath = re.compile(<span class="string">r'.*categoryPath":"(.*?)","describeMap'</span>).findall(script)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 构造包含好评率包的链接</span></span><br><span class="line">        rate_url = <span class="string">"http://product.dangdang.com/index.php?r=comment%2Flist&amp;productId="</span>+str(goodsid)+<span class="string">"&amp;categoryPath="</span>+str(categoryPath)+<span class="string">"&amp;mainProductId="</span>+str(goodsid)</span><br><span class="line">        rate_date = urllib.request.urlopen(rate_url).read().decode(<span class="string">"utf-8"</span>)  <span class="comment"># 读取包含好评率的包的内容</span></span><br><span class="line">        item[<span class="string">"rate"</span>] = re.compile(<span class="string">r'"goodRate":"(.*?)"'</span>).findall(rate_date)[<span class="number">0</span>]+<span class="string">'%'</span>   <span class="comment"># 用正则表达式提取好评率</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>在命令行中执行以下命令开始爬取：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy crawl dd</span><br></pre></td></tr></table></figure><h1 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h1><p><img src="/2018/09/01/基于Scrapy框架的CrawlSpider类爬取当当全网商品信息/结果.png" alt="结果展示"></p>]]></content>
      
      
      <categories>
          
          <category> python3网络爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>基于scrapy框架爬取西刺代理并验证有效性</title>
      <link href="/2018/08/02/%E5%9F%BA%E4%BA%8Escrapy%E6%A1%86%E6%9E%B6%E7%88%AC%E5%8F%96%E8%A5%BF%E5%88%BA%E4%BB%A3%E7%90%86%E5%B9%B6%E9%AA%8C%E8%AF%81%E6%9C%89%E6%95%88%E6%80%A7/"/>
      <url>/2018/08/02/%E5%9F%BA%E4%BA%8Escrapy%E6%A1%86%E6%9E%B6%E7%88%AC%E5%8F%96%E8%A5%BF%E5%88%BA%E4%BB%A3%E7%90%86%E5%B9%B6%E9%AA%8C%E8%AF%81%E6%9C%89%E6%95%88%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在爬取网站数据的时候，一些网站会对用户的访问频率进行限制，如果爬取过快会被封ip，而使用代理可防止被封禁。本项目使用scrapy框架对<a href="http://www.xicidaili.com/" target="_blank" rel="noopener">西刺网站</a>进行爬取，并验证爬取代理的有效性，最终将有效的代理输出并存储到json文件中。</p><p>Github地址: <a href="https://github.com/RunningGump/crawl_xiciproxy" target="_blank" rel="noopener">https://github.com/RunningGump/crawl_xiciproxy</a></p><h1 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h1><ol><li>python3.6</li><li>Scrapy 1.5.0</li></ol><h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><p>首先，我们需要创建一个Scrapy项目，在shell中使用<code>scrapy startproject</code>命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy startproject xiciproxy</span><br><span class="line">New Scrapy project <span class="string">'xiciproxy'</span>, using template directory <span class="string">'/usr/local/lib/python3.6/dist-packages/scrapy/templates/project'</span>, created <span class="keyword">in</span>:</span><br><span class="line">    /home/geng/xiciproxy</span><br><span class="line"></span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> xiciproxy</span><br><span class="line">    scrapy genspider example example.com</span><br></pre></td></tr></table></figure><p>创建好一个名为<code>xiciproject</code>的项目后，接下来，你进入新建的项目目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> xiciproxy</span><br></pre></td></tr></table></figure><p>然后,使用<code>scrapy genspider &lt;name&gt; &lt;domain&gt;</code>创建一个spider：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy genspider xici xicidaili.com</span><br><span class="line">Created spider <span class="string">'xici'</span> using template <span class="string">'basic'</span> <span class="keyword">in</span> module:</span><br><span class="line">  xiciproxy.spiders.xici</span><br></pre></td></tr></table></figure><p>此时，你通过<code>cd ..</code>返回上级目录，使用<code>tree</code>命令查看项目目录下的文件，显示如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ..</span><br><span class="line">$ tree xiciproxy</span><br><span class="line">xiciproxy</span><br><span class="line">├── scrapy.cfg</span><br><span class="line">└── xiciproxy</span><br><span class="line">    ├── __init__.py</span><br><span class="line">    ├── items.py</span><br><span class="line">    ├── middlewares.py</span><br><span class="line">    ├── pipelines.py</span><br><span class="line">    ├── __pycache__</span><br><span class="line">    │   ├── __init__.cpython-36.pyc</span><br><span class="line">    │   └── settings.cpython-36.pyc</span><br><span class="line">    ├── settings.py</span><br><span class="line">    └── spiders</span><br><span class="line">        ├── __init__.py</span><br><span class="line">        ├── __pycache__</span><br><span class="line">        │   └── __init__.cpython-36.pyc</span><br><span class="line">        └── xici.py</span><br><span class="line"></span><br><span class="line">4 directories, 11 files</span><br></pre></td></tr></table></figure><p>到此为止，我们的项目就创建成功了。</p><h1 id="分析页面"><a href="#分析页面" class="headerlink" title="分析页面"></a>分析页面</h1><p>编写爬虫程序之间，首先需要对待爬取的页面进行分析，主流的浏览器中都带有分析页面的工具或插件，这里我们选用Chrome浏览器的开发者工具分析页面。</p><h2 id="链接信息"><a href="#链接信息" class="headerlink" title="链接信息"></a>链接信息</h2><p>在Chrome浏览器中打开页面<a href="http://www.xicidaili.com/" target="_blank" rel="noopener">http://www.xicidaili.com/</a>, 通过点击<code>国内高匿代理</code>和<code>国内普通代理</code>以及进行翻页操作，会发现以下规律：</p><p><code>http://www.xicidaili.com/参数1/参数2</code></p><p>参数1中<code>nn</code>代表高匿代理，<code>nt</code>代表普通代理；参数2中1,2,3,4…代表页数。</p><h2 id="数据信息"><a href="#数据信息" class="headerlink" title="数据信息"></a>数据信息</h2><p>爬取网页信息时一般使用高匿代理，高匿代理不改变客户机的请求，这样在服务器看来就像有个真正的客户浏览器在访问它，这时客户的真是IP是隐藏的，不会认为我们使用了代理。</p><p>本部分以爬取高匿代理为例子来分析如何爬取网页的数据信息。在Chrome浏览器中打开页面<a href="http://www.xicidaili.com/nn" target="_blank" rel="noopener">http://www.xicidaili.com/nn</a>, 并按<code>F12</code>键来打开开发者工具，点击Elements（元素）来查看其HTML代码，会发现每一条代理的信息都包裹在一个<code>tr</code>标签下，如下图所示：</p><p><img src="/2018/08/02/基于scrapy框架爬取西刺代理并验证有效性/xici1.png" alt="一个tr标签对应一条代理信息"></p><p>再来单独对一个<code>tr</code>标签进行分析：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tr</span> <span class="attr">class</span>=<span class="string">"odd"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"country"</span>&gt;</span><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"http://fs.xicidaili.com/images/flag/cn.png"</span> <span class="attr">alt</span>=<span class="string">"Cn"</span>&gt;</span><span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span>115.198.35.213<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span>6666<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/2018-07-20/zhejiang"</span>&gt;</span>浙江杭州<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"country"</span>&gt;</span>高匿<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span>HTTPS<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"country"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">title</span>=<span class="string">"0.144秒"</span> <span class="attr">class</span>=<span class="string">"bar"</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"bar_inner fast"</span> <span class="attr">style</span>=<span class="string">"width:85%"</span>&gt;</span></span><br><span class="line">            </span><br><span class="line">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"country"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">title</span>=<span class="string">"0.028秒"</span> <span class="attr">class</span>=<span class="string">"bar"</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"bar_inner fast"</span> <span class="attr">style</span>=<span class="string">"width:96%"</span>&gt;</span></span><br><span class="line">            </span><br><span class="line">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      </span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span>15天<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span>18-08-04 15:33<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br></pre></td></tr></table></figure><p>会发现：IP地址包裹在<code>td[2]</code>标签下，端口port包裹在<code>td[3]</code>标签下，类型（http/https）包裹在<code>td[6]</code>标签下。</p><h1 id="程序编写"><a href="#程序编写" class="headerlink" title="程序编写"></a>程序编写</h1><p>分析完页面后，接下来编写爬虫。本项目主要是对<code>xici.py</code>进行编写，对<code>settings.py</code>仅做了轻微改动。</p><h2 id="实现spider"><a href="#实现spider" class="headerlink" title="实现spider"></a>实现spider</h2><p>即编写<code>xici.py</code>文件，程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">scrapy crawl xici -o out.json -a num_pages=50 -a typ=nn</span></span><br><span class="line"><span class="string">其中`out.json`是输出有效代理的json文件，`num_pages`是爬取页数，`typ`表示代理类型，`nn`是高匿代理，`nt`是普通代理。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XiCiSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    <span class="comment"># 每一个爬虫的唯一标识</span></span><br><span class="line">    name = <span class="string">'xici'</span></span><br><span class="line">    <span class="comment"># 使用-a选项,可以将命令行参数传递给spider的__init__方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_pages=<span class="number">5</span>, typ=<span class="string">'nn'</span>, *args, **kwargs)</span>:</span></span><br><span class="line">        num_pages = int(num_pages)</span><br><span class="line">        self.num_pages = num_pages</span><br><span class="line">        self.typ = typ</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 定义起始爬取点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span> </span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, self.num_pages + <span class="number">1</span>):</span><br><span class="line">            url = <span class="string">'http://www.xicidaili.com/&#123;&#125;/&#123;&#125;'</span>.format(self.typ, page)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析response返回的网页</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        proxy_list = response.xpath(<span class="string">'//table[@id = "ip_list"]/tr[position()&gt;1]'</span>)  </span><br><span class="line">        <span class="keyword">for</span> tr <span class="keyword">in</span> proxy_list:</span><br><span class="line">            <span class="comment"># 提取代理的 ip, port, scheme(http or https)</span></span><br><span class="line">            ip = tr.xpath(<span class="string">'td[2]/text()'</span>).extract_first()</span><br><span class="line">            port = tr.xpath(<span class="string">'td[3]/text()'</span>).extract_first()</span><br><span class="line">            scheme = tr.xpath(<span class="string">'td[6]/text()'</span>).extract_first()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 使用爬取到的代理再次发送请求到http(s)://httpbin.org/ip, 验证代理是否可用</span></span><br><span class="line">            url = <span class="string">'%s://httpbin.org/ip'</span> % scheme</span><br><span class="line">            proxy = <span class="string">'%s://%s:%s'</span> % (scheme, ip, port)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            meta = &#123;</span><br><span class="line">                <span class="string">'proxy'</span>: proxy,</span><br><span class="line">                <span class="string">'dont_retry'</span>: <span class="keyword">True</span>,</span><br><span class="line">                <span class="string">'download_timeout'</span>: <span class="number">5</span>,</span><br><span class="line">                <span class="comment"># 下面的ip字段是传递给check_available方法的信息,方便检测是否可隐藏ip</span></span><br><span class="line">                <span class="string">'_proxy_ip'</span>:ip,</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url, callback=self.check_available, meta=meta, dont_filter=<span class="keyword">True</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">check_available</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        proxy_ip = response.meta[<span class="string">'_proxy_ip'</span>]</span><br><span class="line">        <span class="comment"># 判断代理是否具有隐藏IP功能</span></span><br><span class="line">        <span class="keyword">if</span> proxy_ip == json.loads(response.text)[<span class="string">'origin'</span>]:</span><br><span class="line">            <span class="keyword">yield</span>&#123;</span><br><span class="line">                <span class="string">'proxy'</span>: response.meta[<span class="string">'proxy'</span>]</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><ul><li>更改USER_AGENT：西刺代理网站会通过识别请求中的user-agent来判断这次请求是真实用户所为还是机器所为。</li><li>不遵守robots协议：网站会通过robots协议告诉搜索引擎那些页面可以抓取，哪些不可以抓取，而robots协议大多不允许抓取有价值的信息，所以咱们不遵守。</li><li>禁用cookies：如果用不到cookies，就不要让服务器知道你的cookies。</li></ul><p>文件<code>settings.py</code>中的改动如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">USER_AGENT = &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36&quot;</span><br><span class="line">ROBOTSTXT_OBEY = True</span><br><span class="line">COOKIES_ENABLED = False</span><br></pre></td></tr></table></figure><p>在编写好<code>xici.py</code>和<code>settings.py</code>后，我们的项目就大功告成啦！</p><h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>使用方法就是在命令行中执行以下命令即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy crawl xici -o out.json -a num_pages=10 -a typ=nn</span><br></pre></td></tr></table></figure><p>其中<code>out.json</code>是最终输出有效代理的json文件，<code>num_pages</code>是爬取页数，<code>typ</code>表示要爬取的代理类型，<code>nn</code>是高匿代理，<code>nt</code>是普通代理。</p><blockquote><p><strong>提示</strong> ：程序在验证代理有效性的过程中，对于无效的代理会抛出超时异常，不要管这些异常，让程序继续执行直到结束。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> python3网络爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> 西刺代理 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
