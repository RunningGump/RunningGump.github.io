<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>824. Goat Latin</title>
      <link href="/2018/11/05/824-Goat-Latin/"/>
      <url>/2018/11/05/824-Goat-Latin/</url>
      
        <content type="html"><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p><strong>山羊拉丁文</strong></p><p>给定一个由空格分割单词的句子 <code>S</code>。每个单词只包含大写或小写字母。</p><p>我们要将句子转换为 <em>“Goat Latin”</em>（一种类似于 猪拉丁文 - Pig Latin 的虚构语言）。</p><p>山羊拉丁文的规则如下：</p><ul><li>如果单词以元音开头（a, e, i, o, u），在单词后添加<code>&quot;ma&quot;</code>。<br>例如，单词<code>&quot;apple&quot;</code>变为<code>&quot;applema&quot;</code>。</li><li>如果单词以辅音字母开头（即非元音字母），移除第一个字符并将它放到末尾，之后再添加<code>&quot;ma&quot;</code>。<br>例如，单词<code>&quot;goat&quot;</code>变为<code>&quot;oatgma&quot;</code>。</li><li>根据单词在句子中的索引，在单词最后添加与索引相同数量的字母<code>&#39;a&#39;</code>，索引从1开始。<br>例如，在第一个单词后添加<code>&quot;a&quot;</code>，在第二个单词后添加<code>&quot;aa&quot;</code>，以此类推。</li></ul><p>返回将 <code>S</code> 转换为山羊拉丁文后的句子。</p><p><strong>示例 1:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: &quot;I speak Goat Latin&quot;</span><br><span class="line">输出: &quot;Imaa peaksmaaa oatGmaaaa atinLmaaaaa&quot;</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: &quot;The quick brown fox jumped over the lazy dog&quot;</span><br><span class="line">输出: &quot;heTmaa uickqmaaa rownbmaaaa oxfmaaaaa umpedjmaaaaaa overmaaaaaaa hetmaaaaaaaa azylmaaaaaaaaa ogdmaaaaaaaaaa&quot;</span><br></pre></td></tr></table></figure><p><strong>说明:</strong></p><ul><li><code>S</code> 中仅包含大小写字母和空格。单词间有且仅有一个空格。</li><li><code>1 &lt;= S.length &lt;= 150</code>。</li></ul><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>此题较简单，先将字符串以<code>&#39;&#39;</code>分开，返回一个包含所有单词的列表，然后遍历列表，分两种情况修改单词即可，最后再将拼接后的字符串返回。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">toGoatLatin</span><span class="params">(self, S)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type S: str</span></span><br><span class="line"><span class="string">        :rtype: str</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        x = S.split(<span class="string">' '</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(x)):</span><br><span class="line">            <span class="keyword">if</span> x[i][<span class="number">0</span>].lower() <span class="keyword">in</span> [<span class="string">'a'</span>, <span class="string">'e'</span>, <span class="string">'i'</span>, <span class="string">'o'</span>, <span class="string">'u'</span>]:</span><br><span class="line">                x[i] = x[i] + <span class="string">'ma'</span> + <span class="string">'a'</span> * (i + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                x[i] = x[i][<span class="number">1</span>:] + x[i][<span class="number">0</span>] + <span class="string">'ma'</span> + <span class="string">'a'</span> * (i + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">' '</span>.join(x)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>483. Smallest Good Base</title>
      <link href="/2018/11/05/483-Smallest-Good-Base/"/>
      <url>/2018/11/05/483-Smallest-Good-Base/</url>
      
        <content type="html"><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p><strong>最小好基数</strong></p><p>对于给定的整数 n, 如果n的k（k&gt;=2）进制数的所有数位全为1，则称 k（k&gt;=2）是 n 的一个<strong><em>好基数</em></strong>。</p><p>以字符串的形式给出 n, 以字符串的形式返回 n 的最小好进制。</p><p><strong>示例 1：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：&quot;13&quot;</span><br><span class="line">输出：&quot;3&quot;</span><br><span class="line">解释：13 的 3 进制是 111。</span><br></pre></td></tr></table></figure><p><strong>示例 2：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：&quot;4681&quot;</span><br><span class="line">输出：&quot;8&quot;</span><br><span class="line">解释：4681 的 8 进制是 11111。</span><br></pre></td></tr></table></figure><p><strong>示例 3：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：&quot;1000000000000000000&quot;</span><br><span class="line">输出：&quot;999999999999999999&quot;</span><br><span class="line">解释：1000000000000000000 的 999999999999999999 进制是 11。</span><br></pre></td></tr></table></figure><p><strong>提示：</strong></p><ol><li>n的取值范围是 [3, 10^18]。</li><li>输入总是有效且没有前导 0。</li></ol><h1 id="思路一"><a href="#思路一" class="headerlink" title="思路一"></a>思路一</h1><p>输入给定数为n，我们遍历[<code>2</code> , <code>n-1</code>]</p><p>​        如果当前遍历值<code>i</code>为<code>n</code>的基数，则找到了最小好基数</p><blockquote><p>注意，<code>n-1</code>一定是<code>n</code>的一个好基数</p></blockquote><p>那么，如何判断<code>i</code>为<code>n</code>的好基数呢？</p><p>若<code>i</code>为<code>n</code>的好基数，由辗转相除法的逆过程可知，<code>n</code>和<code>i</code>一定满足这样一个关系：</p><p>$ ((( 1 <em> k + 1)</em>k + 1)<em>k + 1)</em>k+1……=n$ ，其中k为基数。</p><h1 id="代码一"><a href="#代码一" class="headerlink" title="代码一"></a>代码一</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">smallestGoodBase</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">checkBase</span><span class="params">(base, n)</span>:</span></span><br><span class="line">            currentVal = <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> currentVal &lt; n:</span><br><span class="line">                currentVal = currentVal * base + <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> currentVal == n</span><br><span class="line">        </span><br><span class="line">        thisNum = int(n)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, thisNum):</span><br><span class="line">            <span class="keyword">if</span> checkBase(i, thisNum):</span><br><span class="line">                <span class="keyword">return</span> str(i)</span><br></pre></td></tr></table></figure><h1 id="思路二"><a href="#思路二" class="headerlink" title="思路二"></a>思路二</h1><p>先利用数学知识对问题进行分析，将问题简化，然后在去用代码实现。</p><p>n 为输入的整数，k为基，m为多项式的个数，根据好基数的定义知，n可以展开为如下式子：</p><p>$n=1+k+k^2+…+k^{m-1}     \tag{1}$</p><p>可以明显看出，（1）式中的元素为等比数列。根据等比数列求和公式得：</p><p>$n=\frac{k^m-1}{k-1}     \tag{2}$</p><p>此题中基数k&gt;=2 ，我们要求的是最小的好基数，即求使（1）式成立的最小的k。观察式子可以发现，当n恒定的时候，k越小则m越大，m代表多项式的个数，由于k至少为2，那么（1）式肯定至少有两项，则m&gt;=2。m的最大值是多少呢？当k取最小值2时，m的值最大，即数字n用二进制表示的时候可拆分出的项最多，计算得到m最大为$int(log_2(m+1)) + 1$，所以，</p><p>$ 2&lt;= m &lt;int(log_2(m+1)) + 1     \tag{3}$</p><p>从（1）式中可以明显看出：$k^{m-1}&lt;n$，将（3）式进行变形可得 $ k&lt;n^{ \frac{1}{m-1} }$。此时会想到，如果$n^{ m-1}&lt;k+1$也成立的话，就会为我们的计算带来很大的方便，因为如果$ k&lt;n^{ \frac{1}{m-1} }&lt;k+1$ 的话，我们对$ n^{ \frac{1}{m-1} }$取整就可以得到k的值。事实上，(4) 式确实是成立的。</p><p>$n^{ \frac{1}{m-1} }&lt;k+1    \tag{4}$</p><p>由（4）式可得，</p><p>$n&lt;(k+1)^{m-1}     \tag{5}$ </p><p>将（5）右边的式子进行牛顿二项式展开，与（1）式进行比对，可明显看出（5）式是成立的。</p><h1 id="代码二"><a href="#代码二" class="headerlink" title="代码二"></a>代码二</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math   </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">smallestGoodBase</span><span class="params">(self, n)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type n: str</span></span><br><span class="line"><span class="string">        :rtype: str</span></span><br><span class="line"><span class="string">        """</span>        </span><br><span class="line">        num = int(n)</span><br><span class="line">        thisLen = int(math.log(num,<span class="number">2</span>)) + <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> thisLen &gt; <span class="number">2</span>:</span><br><span class="line">            thisBase = int(num ** (<span class="number">1.0</span>/(thisLen - <span class="number">1</span>)))</span><br><span class="line">            <span class="keyword">if</span> num * (thisBase - <span class="number">1</span>) == thisBase ** thisLen - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> str(thisBase)</span><br><span class="line">            thisLen -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> str(num - <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p><code>if num * (thisBase - 1) == thisBase ** thisLen - 1:</code>不能写成<code>if num == (base**goodBaseLen - 1) / (base - 1):</code>，因为计算机精度的问题，当输入n很大时，一些测试用例会因为精度问题导致后面的表达式出错。所以，在计算机的运算式中，能用乘法表示就不用除法。</p>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>925. Long Pressed Name</title>
      <link href="/2018/11/02/925-Long-Pressed-Name/"/>
      <url>/2018/11/02/925-Long-Pressed-Name/</url>
      
        <content type="html"><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p><strong>长按键入</strong></p><p>你的朋友正在使用键盘输入他的名字 <code>name</code>。偶尔，在键入字符 <code>c</code> 时，按键可能会被<em>长按</em>，而字符可能被输入 1 次或多次。</p><p>你将会检查键盘输入的字符 <code>typed</code>。如果它对应的可能是你的朋友的名字（其中一些字符可能被长按），那么就返回 <code>True</code>。</p><p><strong>示例 1：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：name = &quot;alex&quot;, typed = &quot;aaleex&quot;</span><br><span class="line">输出：true</span><br><span class="line">解释：&apos;alex&apos; 中的 &apos;a&apos; 和 &apos;e&apos; 被长按。</span><br></pre></td></tr></table></figure><p><strong>示例 2：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：name = &quot;saeed&quot;, typed = &quot;ssaaedd&quot;</span><br><span class="line">输出：false</span><br><span class="line">解释：&apos;e&apos; 一定需要被键入两次，但在 typed 的输出中不是这样。</span><br></pre></td></tr></table></figure><p><strong>示例 3：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：name = &quot;leelee&quot;, typed = &quot;lleeelee&quot;</span><br><span class="line">输出：true</span><br></pre></td></tr></table></figure><p><strong>示例 4：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：name = &quot;laiden&quot;, typed = &quot;laiden&quot;</span><br><span class="line">输出：true</span><br><span class="line">解释：长按名字中的字符并不是必要的。</span><br></pre></td></tr></table></figure><p><strong>提示：</strong></p><ol><li><code>name.length &lt;= 1000</code></li><li><code>typed.length &lt;= 1000</code></li><li><code>name</code> 和 <code>typed</code> 的字符都是小写字母。</li></ol><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>使用两个指针解决这个问题。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a l e x</span><br><span class="line">i</span><br><span class="line">a a l e e x</span><br><span class="line">j</span><br></pre></td></tr></table></figure><p>若<code>i&lt;name.length()</code> 且<code>name.charAt(i)==typed.charAt(j)</code>,则<code>i++;j++</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a l e x</span><br><span class="line">  i</span><br><span class="line">a a l e e x</span><br><span class="line">  j</span><br></pre></td></tr></table></figure><p>若<code>j==0 或 typed.charAt(j)!= typed.charAt(j-1)</code>，则返回false。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a l e x</span><br><span class="line">  i</span><br><span class="line">a a l e e x</span><br><span class="line">    j</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a l e x</span><br><span class="line">    i</span><br><span class="line">a a l e e x</span><br><span class="line">      j</span><br></pre></td></tr></table></figure><p>…..</p><p>…..</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a l e x</span><br><span class="line">        i</span><br><span class="line">a a l e e x</span><br><span class="line">          j</span><br></pre></td></tr></table></figure><blockquote><p>注意：&amp;&amp;的运算符，运算顺序从左至右。若&amp;&amp;左边的表达式为false，则不进行&amp;&amp;后面的运算，这个逻辑表达式返回false。</p></blockquote><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isLongPressedName</span><span class="params">(String name, String typed)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> typed_len = typed.length();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;typed_len; j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i&lt;name.length() &amp;&amp; name.charAt(i)==typed.charAt(j))&#123;</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">if</span>(j==<span class="number">0</span> || typed.charAt(j)!= typed.charAt(j-<span class="number">1</span>))</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> i==name.length();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>268. Missing Number</title>
      <link href="/2018/11/02/268-Missing-Number/"/>
      <url>/2018/11/02/268-Missing-Number/</url>
      
        <content type="html"><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p><strong>缺失数字</strong></p><p>给定一个包含 <code>0, 1, 2, ..., n</code> 中 <em>n</em> 个数的序列，找出 0 .. <em>n</em> 中没有出现在序列中的那个数。</p><p><strong>示例 1:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: [3,0,1]</span><br><span class="line">输出: 2</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: [9,6,4,2,3,5,7,0,1]</span><br><span class="line">输出: 8</span><br></pre></td></tr></table></figure><p><strong>说明:</strong><br>你的算法应具有线性时间复杂度。你能否仅使用额外常数空间来实现?</p><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>认真审题；如果使用先排序在二分查找的策略，时间复杂度上明显会大于O(n)。在这里将其看作一道数学题解答就好了。根据序列长度n，可以求出不缺失数字时的和。数字缺失之后的和通过遍历一遍数组得到。最后二者相减就是要找的缺失数字。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">missingNumber</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = nums.length;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)&#123;</span><br><span class="line">            sum += nums[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> n*(n+<span class="number">1</span>)/<span class="number">2</span> - sum;    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> LeetCode </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>排序后的数组删除重复（次数大于2）数字</title>
      <link href="/2018/10/31/%E6%8E%92%E5%BA%8F%E5%90%8E%E7%9A%84%E6%95%B0%E7%BB%84%E5%88%A0%E9%99%A4%E9%87%8D%E5%A4%8D%EF%BC%88%E6%AC%A1%E6%95%B0%E5%A4%A7%E4%BA%8E2%EF%BC%89%E6%95%B0%E5%AD%97/"/>
      <url>/2018/10/31/%E6%8E%92%E5%BA%8F%E5%90%8E%E7%9A%84%E6%95%B0%E7%BB%84%E5%88%A0%E9%99%A4%E9%87%8D%E5%A4%8D%EF%BC%88%E6%AC%A1%E6%95%B0%E5%A4%A7%E4%BA%8E2%EF%BC%89%E6%95%B0%E5%AD%97/</url>
      
        <content type="html"><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p>给定升序排序的数组，如果数组有2个以上相同的数字，去掉他们，直到剩下2个为止。</p><p>例如：</p><p>数组A[] = [1,1,1,2,2,3]</p><p>你的算法需要返回新数组的长度5,</p><p>此时A为[1,1,2,2,3]</p><p>格式：第一行输入一个数字n，第二行输入A[n],</p><p>最后输出新数组的长度。</p><p>样例输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">6</span><br><span class="line">1 1 1 1 3 3</span><br></pre></td></tr></table></figure><p>样例输出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">4</span><br></pre></td></tr></table></figure><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>从第3个数开始遍历到最后</p><p>​    如果当前位置的数字和其前两个数字都相等，则count减1</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> jisuanke;</span><br><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RmDuplicateNum</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">Scanner sc = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line"><span class="keyword">int</span> n = sc.nextInt(); <span class="comment">// 输入数组长度</span></span><br><span class="line"><span class="keyword">int</span>[] A = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 通过for循环输入数组内容</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n;i++) &#123;</span><br><span class="line">A[i] = sc.nextInt();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> count = n;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>; i&lt;n; i++) &#123;</span><br><span class="line"><span class="keyword">if</span>(A[i]==A[i-<span class="number">1</span>] &amp;&amp; A[i]==A[i-<span class="number">2</span>]) &#123;</span><br><span class="line">count--;</span><br><span class="line">&#125;                                                                                                                                                 </span><br><span class="line">&#125;</span><br><span class="line">System.out.println(count);  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 计蒜客 </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>进制转换</title>
      <link href="/2018/10/31/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/"/>
      <url>/2018/10/31/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p>实现10进制数到任意进制(2~9)的转换。</p><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>辗转相除法，除n倒取余。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> jisuanke;</span><br><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DecimalConversion</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">Scanner input = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line"><span class="keyword">int</span> d = input.nextInt(); <span class="comment">// 输入需要转换的十进制数</span></span><br><span class="line"><span class="keyword">int</span> k = input.nextInt(); <span class="comment">// 输入进行多少进制的转换（2-9）</span></span><br><span class="line">trans(d,k);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">trans</span><span class="params">(<span class="keyword">int</span> d, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> a[] = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">1024</span>];</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">0</span>;d!=<span class="number">0</span>;i++) &#123;</span><br><span class="line">a[i] = d % k;</span><br><span class="line">d = d/k;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(i--;i&gt;=<span class="number">0</span>;i--) &#123;</span><br><span class="line">System.out.print(a[i]);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 计蒜客 </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>Hexo博客迁移到一台新电脑</title>
      <link href="/2018/10/29/Hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E5%88%B0%E5%8F%A6%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91/"/>
      <url>/2018/10/29/Hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E5%88%B0%E5%8F%A6%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>由于10月份换了一台Macbook Pro，导致自己搭建的Hexo博客一直停滞了。我想人做事一定要善始善终，不要忘记当初搭建Hexo博客的初心。于是乎，就有了这一篇文章。</p><h1 id="迁移思路"><a href="#迁移思路" class="headerlink" title="迁移思路"></a>迁移思路</h1><p>在已经推送到Github上的Hexo静态网页创建一个分支，利用这个分支来管理自己的Hexo环境文件。</p><h1 id="迁移步骤"><a href="#迁移步骤" class="headerlink" title="迁移步骤"></a>迁移步骤</h1><h2 id="1-在旧机器上克隆Github上面生成的静态文件到本地"><a href="#1-在旧机器上克隆Github上面生成的静态文件到本地" class="headerlink" title="1.在旧机器上克隆Github上面生成的静态文件到本地"></a>1.在旧机器上克隆Github上面生成的静态文件到本地</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/username/username.github.io.git</span><br></pre></td></tr></table></figure><h2 id="2-针对克隆到本地的文件中，将除去-git文件的所有文件都删除"><a href="#2-针对克隆到本地的文件中，将除去-git文件的所有文件都删除" class="headerlink" title="2.针对克隆到本地的文件中，将除去.git文件的所有文件都删除"></a>2.针对克隆到本地的文件中，将除去<code>.git</code>文件的所有文件都删除</h2><h2 id="3-将旧机器中所有文件-gitignore文件中包含的文件除外）拷贝到我们克隆下来的文件内"><a href="#3-将旧机器中所有文件-gitignore文件中包含的文件除外）拷贝到我们克隆下来的文件内" class="headerlink" title="3.将旧机器中所有文件(.gitignore文件中包含的文件除外）拷贝到我们克隆下来的文件内"></a>3.将旧机器中所有文件(<code>.gitignore</code>文件中包含的文件除外）拷贝到我们克隆下来的文件内</h2><h2 id="4-创建并切换到一个叫hexo的分支"><a href="#4-创建并切换到一个叫hexo的分支" class="headerlink" title="4. 创建并切换到一个叫hexo的分支"></a>4. 创建并切换到一个叫hexo的分支</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b hexo</span><br></pre></td></tr></table></figure><h2 id="5-提交复制过来的文件到暂存取"><a href="#5-提交复制过来的文件到暂存取" class="headerlink" title="5. 提交复制过来的文件到暂存取"></a>5. 提交复制过来的文件到暂存取</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add -A</span><br></pre></td></tr></table></figure><h2 id="6-提交"><a href="#6-提交" class="headerlink" title="6.提交"></a>6.提交</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m <span class="string">"ceate a new branch file"</span></span><br></pre></td></tr></table></figure><h2 id="7-推送到Github"><a href="#7-推送到Github" class="headerlink" title="7.推送到Github"></a>7.推送到Github</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push --<span class="built_in">set</span>-upstream origin hexo</span><br></pre></td></tr></table></figure><p>这个时候hexo分支已经创建完毕，接下来，我们在新电脑上搭建环境。</p><h2 id="8-新电脑配置环境"><a href="#8-新电脑配置环境" class="headerlink" title="8.新电脑配置环境"></a>8.新电脑配置环境</h2><p>安装node.js，根据自己电脑系统自行百度安装。</p><p>安装git，git相关教程推荐<a href="https://link.jianshu.com/?t=https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">廖雪峰老师的git教程</a>。</p><p>安装hexo： <code>npm install -g hexo-cli</code></p><h2 id="9-clone远程仓库到本地"><a href="#9-clone远程仓库到本地" class="headerlink" title="9.clone远程仓库到本地"></a>9.clone远程仓库到本地</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> -b hexo https://github.com/username/username.github.io.git</span><br></pre></td></tr></table></figure><h2 id="10-根据package-json安装依赖"><a href="#10-根据package-json安装依赖" class="headerlink" title="10.根据package.json安装依赖"></a>10.根据<code>package.json</code>安装依赖</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install *** --save</span><br></pre></td></tr></table></figure><p>将<code>***</code>替换为<code>package.json</code>文件内的依赖包</p><h2 id="11-开始写文章"><a href="#11-开始写文章" class="headerlink" title="11.开始写文章"></a>11.开始写文章</h2><p>我们现在可以通过<code>hexo n &quot;文章标题&quot;</code> 创建一篇文章了！</p><h2 id="12-提交hexo环境文件"><a href="#12-提交hexo环境文件" class="headerlink" title="12.  提交hexo环境文件"></a>12.  提交hexo环境文件</h2><p><code>git add .</code></p><p><code>git commit -m &quot;some description&quot;</code></p><p><code>git push origin hexo</code></p><h2 id="13-发布文章"><a href="#13-发布文章" class="headerlink" title="13.发布文章"></a>13.发布文章</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure><p>到这里，我们的Hexo博客就迁移完毕了！！以后再写文章时，只需要重复步骤11、12、13就ok啦！！</p>]]></content>
      
      
      <categories>
          
          <category> “Hexo” </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo迁移 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>基于Scrapy框架的CrawlSpider类爬取当当全网商品信息</title>
      <link href="/2018/09/01/%E5%9F%BA%E4%BA%8EScrapy%E6%A1%86%E6%9E%B6%E7%9A%84CrawlSpider%E7%B1%BB%E7%88%AC%E5%8F%96%E5%BD%93%E5%BD%93%E5%85%A8%E7%BD%91%E5%95%86%E5%93%81%E4%BF%A1%E6%81%AF/"/>
      <url>/2018/09/01/%E5%9F%BA%E4%BA%8EScrapy%E6%A1%86%E6%9E%B6%E7%9A%84CrawlSpider%E7%B1%BB%E7%88%AC%E5%8F%96%E5%BD%93%E5%BD%93%E5%85%A8%E7%BD%91%E5%95%86%E5%93%81%E4%BF%A1%E6%81%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本项目通过使用Scrapy框架的CrawlSpider类，对当当全网商品信息进行爬取并将信息保存至mysql数据库，当当网反爬措施是对IP访问频率的限制，所以本项目使用了中间件<code>scrapy-rotating-proxies</code>来管控IP代理池，有关代理ip的爬取请见我的另一篇博文。</p><p>CrawlSpider是Spider的派生类，Spider类的设计原则是只爬取start_url列表中的网页，而CrawlSpider类通过定义一些规则(rule)来跟进所爬取网页中的link，从爬取的网页中获取link并继续爬取。</p><p>Github地址: <a href="https://github.com/RunningGump/crawl_dangdang" target="_blank" rel="noopener">https://github.com/RunningGump/crawl_dangdang</a></p><h1 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h1><ol><li>scrapy 1.5.0</li><li>python3.6</li><li>mysql 5.7</li><li>pymysql 库</li><li>scrapy-rotating-proxies 库</li><li>fake-useragent 库</li></ol><h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><p>首先，我们需要创建一个Scrapy项目，在shell中使用<code>scrapy startproject</code>命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy startproject Dangdang</span><br><span class="line">New Scrapy project <span class="string">'Dangdang'</span>, using template directory <span class="string">'/usr/local/lib/python3.6/dist-packages/scrapy/templates/project'</span>, created <span class="keyword">in</span>:</span><br><span class="line">    /home/geng/Dangdang</span><br><span class="line"></span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> Dangdang</span><br><span class="line">    scrapy genspider example example.com</span><br></pre></td></tr></table></figure><p>创建好一个名为<code>Dangdang</code>的项目后，接下来，你进入新建的项目目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> Dangdang</span><br></pre></td></tr></table></figure><p>然后,使用<code>scrapy genspider -t &lt;template&gt; &lt;name&gt; &lt;domain&gt;</code>创建一个spider：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy genspider -t crawl dd dangdang.com</span><br><span class="line">Created spider <span class="string">'dd'</span> using template <span class="string">'crawl'</span> <span class="keyword">in</span> module:</span><br><span class="line">  Dangdang.spiders.dd</span><br></pre></td></tr></table></figure><p>此时，你通过<code>cd ..</code>返回上级目录，使用<code>tree</code>命令查看项目目录下的文件，显示如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ..</span><br><span class="line">$ tree Dangdang/</span><br><span class="line">Dangdang/</span><br><span class="line">├── Dangdang</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── __pycache__</span><br><span class="line">│   │   ├── __init__.cpython-36.pyc</span><br><span class="line">│   │   └── settings.cpython-36.pyc</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       ├── dd.py</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── __pycache__</span><br><span class="line">│           └── __init__.cpython-36.pyc</span><br><span class="line">└── scrapy.cfg</span><br><span class="line"></span><br><span class="line">4 directories, 11 files</span><br></pre></td></tr></table></figure><p>到此为止，我们的项目就创建成功了。</p><h1 id="rules"><a href="#rules" class="headerlink" title="rules"></a>rules</h1><p>在rules中包含一个或多个Rule对象，每个Rule对爬取网站的动作设置了爬取规则。</p><p> <strong>参数介绍：</strong></p><p><code>link_extractor</code>：是一个Link Extractor对象，用于定义需要提取的链接。</p><p><code>callback</code>： 回调函数，对link_extractor获得的链接进行处理与解析。</p><p><strong>注意事项：</strong>当编写爬虫规则时，避免使用parse作为回调函数。由于CrawlSpider使用parse方法来实现其逻辑，如果覆盖了 parse方法，crawl spider将会运行失败。</p><p><code>follow</code>：是一个布尔(boolean)值，指定了根据规则从response提取的链接是否需要跟进。 如果callback为None，follow 默认设置为True ，否则默认为False</p><p><code>process_links</code>：指定该spider中哪个的函数将会被调用，从link_extractor中获取到链接列表时将会调用该函数。该方法主要用来过滤链接。          </p><p><code>process_request</code>：指定该spider中哪个的函数将会被调用， 该规则提取到每个request时都会调用该函数。 (用来过滤request)</p><h1 id="LinkExtrator"><a href="#LinkExtrator" class="headerlink" title="LinkExtrator"></a>LinkExtrator</h1><p><strong>参数介绍：</strong></p><p><code>allow</code>：满足括号中“正则表达式”的值会被提取，如果为空，则全部匹配。</p><p><code>deny</code>：与这个正则表达式(或正则表达式列表)匹配的URL不提取。</p><p><code>allow_domains</code>：会被提取的链接的域名。</p><p><code>deny_domains</code>：不会被提取链接的域名。</p><p><code>restrict_xpaths</code>：使用Xpath表达式与allow共同作用提取出同时符合对应Xpath表达式和正则表达式的链接；</p><h1 id="项目代码"><a href="#项目代码" class="headerlink" title="项目代码"></a>项目代码</h1><h2 id="编写item-py文件"><a href="#编写item-py文件" class="headerlink" title="编写item.py文件"></a>编写item.py文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DangdangItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    category = scrapy.Field()  <span class="comment"># 商品类别</span></span><br><span class="line">    title = scrapy.Field()    <span class="comment"># 商品名称</span></span><br><span class="line">    link = scrapy.Field()    <span class="comment"># 商品链接</span></span><br><span class="line">    price = scrapy.Field()   <span class="comment"># 商品价格</span></span><br><span class="line">    comment = scrapy.Field()  <span class="comment"># 商品评论数</span></span><br><span class="line">    rate = scrapy.Field()    <span class="comment"># 商品的好评率</span></span><br><span class="line">    source = scrapy.Field()      <span class="comment"># 商品的来源地</span></span><br><span class="line">    detail = scrapy.Field()   <span class="comment"># 商品详情</span></span><br><span class="line">    img_link = scrapy.Field() <span class="comment"># 商品图片链接</span></span><br></pre></td></tr></table></figure><h2 id="编写pipeline-py文件"><a href="#编写pipeline-py文件" class="headerlink" title="编写pipeline.py文件"></a>编写pipeline.py文件</h2><p>需提前创建好数据库，本项目创建的数据库名字为<code>dd</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">from</span> scrapy.conf <span class="keyword">import</span> settings</span><br><span class="line"></span><br><span class="line"><span class="comment">## pipeline默认是不开启的，需在settings.py中开启</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DangdangPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="comment">##建立数据库连接</span></span><br><span class="line">        conn = pymysql.connect(host=<span class="string">"localhost"</span>,user=<span class="string">"root"</span>,passwd=<span class="string">'yourpasswd'</span>,db=<span class="string">"dd"</span>,use_unicode=<span class="keyword">True</span>, charset=<span class="string">"utf8"</span>)</span><br><span class="line">        cur = conn.cursor()             <span class="comment"># 用来获得python执行Mysql命令的方法,也就是我们所说的操作游标</span></span><br><span class="line">        print(<span class="string">"mysql connect success"</span>)  <span class="comment"># 测试语句，这在程序执行时非常有效的理解程序是否执行到这一步</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            category = item[<span class="string">"category"</span>]</span><br><span class="line">            title = item[<span class="string">"title"</span>]</span><br><span class="line">            <span class="keyword">if</span> len(title)&gt;<span class="number">40</span>:</span><br><span class="line">                title = title[<span class="number">0</span>:<span class="number">40</span>] + <span class="string">'...'</span></span><br><span class="line">            link = item[<span class="string">"link"</span>]</span><br><span class="line">            img_link = item[<span class="string">'img_link'</span>]</span><br><span class="line">            price = item[<span class="string">"price"</span>]</span><br><span class="line">            comment = item[<span class="string">"comment"</span>]</span><br><span class="line">            rate = item[<span class="string">"rate"</span>]</span><br><span class="line">            source = item[<span class="string">"source"</span>]</span><br><span class="line">            detail = item[<span class="string">"detail"</span>]</span><br><span class="line"></span><br><span class="line">            sql = <span class="string">"INSERT INTO goods(category,title,price,comment,rate,source,detail,link,img_link) VALUES ('%s','%s','%s','%s','%s','%s','%s','%s','%s')"</span> % (category,title,price,comment,rate,source,detail,link,img_link)</span><br><span class="line">            print(sql)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> err:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            cur.execute(sql)         <span class="comment"># 真正执行MySQL语句，即查询TABLE_PARAMS表的数据</span></span><br><span class="line">            print(<span class="string">"insert success"</span>)  <span class="comment"># 测试语句</span></span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> err:</span><br><span class="line">            print(err)</span><br><span class="line">            conn.rollback() <span class="comment">#事务回滚,为了保证数据的有效性将数据恢复到本次操作之前的状态.有时候会存在一个事务包含多个操作，而多个操作又都有顺序，顺序执行操作时，有一个执行失败，则之前操作成功的也会回滚，即未操作的状态</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conn.commit()   <span class="comment">#当没有发生异常时，提交事务，避免出现一些不必要的错误</span></span><br><span class="line">            </span><br><span class="line">        conn.close()  <span class="comment">#关闭连接</span></span><br><span class="line">        <span class="keyword">return</span> item   <span class="comment">#框架要求返回一个item对象</span></span><br></pre></td></tr></table></figure><h2 id="编写middlewares-py"><a href="#编写middlewares-py" class="headerlink" title="编写middlewares.py"></a>编写middlewares.py</h2><p>本项目添加了<code>RandomUserAgentMiddleWare</code>中间件，用来随机更换UserAgent。在<code>middlewares.py</code>文件的最后面添加如下中间件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomUserAgentMiddleWare</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    随机更换User-Agent</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,crawler)</span>:</span></span><br><span class="line">        super(RandomUserAgentMiddleWare, self).__init__()</span><br><span class="line">        self.ua = UserAgent()</span><br><span class="line">        self.ua_type = crawler.settings.get(<span class="string">"RANDOM_UA_TYPE"</span>, <span class="string">"random"</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> cls(crawler)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">get_ua_type</span><span class="params">()</span>:</span></span><br><span class="line">            <span class="keyword">return</span> getattr(self.ua, self.ua_type)   <span class="comment"># 取对象 ua 的 ua_type 的这个属性, 相当于 self.ua.self.ua_type</span></span><br><span class="line"></span><br><span class="line">        request.headers.setdefault(<span class="string">'User-Agent'</span>, get_ua_type())</span><br></pre></td></tr></table></figure><h2 id="修改settings-py-文件"><a href="#修改settings-py-文件" class="headerlink" title="修改settings.py 文件"></a>修改settings.py 文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">BOT_NAME = <span class="string">'Dangdang'</span></span><br><span class="line"></span><br><span class="line">SPIDER_MODULES = [<span class="string">'Dangdang.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'Dangdang.spiders'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不遵循robots协议</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载延迟设置为0，提高爬取速度</span></span><br><span class="line">DOWNLOAD_DELAY = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#禁用Cookie(默认情况下启用)</span></span><br><span class="line">COOKIES_ENABLED = <span class="keyword">False</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用所需要的下载中间件</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'rotating_proxies.middlewares.RotatingProxyMiddleware'</span>: <span class="number">610</span>,</span><br><span class="line">    <span class="string">'rotating_proxies.middlewares.BanDetectionMiddleware'</span>: <span class="number">620</span>,</span><br><span class="line">    <span class="string">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span>: <span class="keyword">None</span>,</span><br><span class="line">    <span class="string">'Dangdang.middlewares.RandomUserAgentMiddleWare'</span>: <span class="number">400</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 代理IP文件路径,此处需改为你自己的路径</span></span><br><span class="line">ROTATING_PROXY_LIST_PATH = <span class="string">'/home/geng/Projects/Dangdang/proxy.txt'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机更换UserAgent </span></span><br><span class="line">RANDOM_UA_TYPE = <span class="string">"random"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启pipeline</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'Dangdang.pipelines.DangdangPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="spider文件-dd-py-编写"><a href="#spider文件-dd-py-编写" class="headerlink" title="spider文件(dd.py)编写"></a>spider文件(dd.py)编写</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">from</span> Dangdang.items <span class="keyword">import</span> DangdangItem</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DdSpider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'dd'</span></span><br><span class="line">    allowed_domains = [<span class="string">'dangdang.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://category.dangdang.com/'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分析网页链接，编写rules规则,提取商品详情页的链接</span></span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r'/cp\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.html$|/pg\d+-cp\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.html$'</span>, deny=<span class="string">r'/cp98.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.html'</span>),</span><br><span class="line">             follow=<span class="keyword">True</span>),</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r'/cid\d+.html$|/pg\d+-cid\d+.html$'</span>, deny=<span class="string">r'/cp98.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.\d&#123;2&#125;.html'</span>),</span><br><span class="line">             follow=<span class="keyword">True</span>),</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r'product.dangdang.com/\d+.html$'</span>, restrict_xpaths=(<span class="string">"//p[@class='name']/a"</span>)),</span><br><span class="line">             callback=<span class="string">'parse_item'</span>,</span><br><span class="line">             follow=<span class="keyword">False</span>),      <span class="comment"># allow与restrict_xpath配合使用,效果很好,可以更精准筛选链接.</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析商品详情页面</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = DangdangItem()  <span class="comment"># 实例化item</span></span><br><span class="line">        item[<span class="string">"category"</span>] = response.xpath(<span class="string">'//*[@id="breadcrumb"]/a[1]/b/text()'</span>).extract_first()+<span class="string">'&gt;'</span>+response.xpath(<span class="string">'//*[@id="breadcrumb"]/a[2]/text()'</span>).extract_first()+<span class="string">'&gt;'</span>+response.xpath(<span class="string">'//*[@id="breadcrumb"]/a[3]/text()'</span>).extract_first()</span><br><span class="line">        item[<span class="string">"title"</span>] = response.xpath(<span class="string">"//*[@id='product_info']/div[1]/h1/@title"</span>).extract_first()</span><br><span class="line">        item[<span class="string">"detail"</span>] = json.dumps(response.xpath(<span class="string">"//*[@id='detail_describe']/ul//li/text()"</span>).extract(),ensure_ascii=<span class="keyword">False</span>)</span><br><span class="line">        item[<span class="string">"link"</span>] = response.url</span><br><span class="line">        item[<span class="string">"img_link"</span>] =json.dumps(response.xpath(<span class="string">"//div[@class='img_list']/ul//li/a/@data-imghref"</span>).extract())</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            item[<span class="string">"price"</span>] = response.xpath(<span class="string">"//*[@id='dd-price']/text()"</span>).extract()[<span class="number">1</span>].strip()</span><br><span class="line">        <span class="keyword">except</span> IndexError <span class="keyword">as</span> e:</span><br><span class="line">            item[<span class="string">"price"</span>] = response.xpath(<span class="string">"//*[@id='dd-price']/text()"</span>).extract()[<span class="number">0</span>].strip()</span><br><span class="line">            item[<span class="string">"comment"</span>] = response.xpath(<span class="string">"//*[@id='comm_num_down']/text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            item[<span class="string">"source"</span>] = response.xpath(<span class="string">"//*[@id='shop-geo-name']/text()"</span>).extract()[<span class="number">0</span>].replace(<span class="string">'\xa0至'</span>,<span class="string">''</span>)</span><br><span class="line">        <span class="keyword">except</span> IndexError <span class="keyword">as</span> e:</span><br><span class="line">            item[<span class="string">"source"</span>] = <span class="string">'当当自营'</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 通过抓包分析,提取商品的好评率</span></span><br><span class="line">        goodsid = re.compile(<span class="string">'\/(\d+).html'</span>).findall(response.url)[<span class="number">0</span>]  <span class="comment"># 提取url中的商品id</span></span><br><span class="line">        <span class="comment"># 提取详情页源码中的categoryPath</span></span><br><span class="line">        script = response.xpath(<span class="string">"/html/body/script[1]/text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        categoryPath = re.compile(<span class="string">r'.*categoryPath":"(.*?)","describeMap'</span>).findall(script)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 构造包含好评率包的链接</span></span><br><span class="line">        rate_url = <span class="string">"http://product.dangdang.com/index.php?r=comment%2Flist&amp;productId="</span>+str(goodsid)+<span class="string">"&amp;categoryPath="</span>+str(categoryPath)+<span class="string">"&amp;mainProductId="</span>+str(goodsid)</span><br><span class="line">        rate_date = urllib.request.urlopen(rate_url).read().decode(<span class="string">"utf-8"</span>)  <span class="comment"># 读取包含好评率的包的内容</span></span><br><span class="line">        item[<span class="string">"rate"</span>] = re.compile(<span class="string">r'"goodRate":"(.*?)"'</span>).findall(rate_date)[<span class="number">0</span>]+<span class="string">'%'</span>   <span class="comment"># 用正则表达式提取好评率</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>在命令行中执行以下命令开始爬取：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy crawl dd</span><br></pre></td></tr></table></figure><h1 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h1><p><img src="/2018/09/01/基于Scrapy框架的CrawlSpider类爬取当当全网商品信息/结果.png" alt="结果展示"></p>]]></content>
      
      
      <categories>
          
          <category> python3网络爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>基于scrapy框架爬取西刺代理并验证有效性</title>
      <link href="/2018/08/02/%E5%9F%BA%E4%BA%8Escrapy%E6%A1%86%E6%9E%B6%E7%88%AC%E5%8F%96%E8%A5%BF%E5%88%BA%E4%BB%A3%E7%90%86%E5%B9%B6%E9%AA%8C%E8%AF%81%E6%9C%89%E6%95%88%E6%80%A7/"/>
      <url>/2018/08/02/%E5%9F%BA%E4%BA%8Escrapy%E6%A1%86%E6%9E%B6%E7%88%AC%E5%8F%96%E8%A5%BF%E5%88%BA%E4%BB%A3%E7%90%86%E5%B9%B6%E9%AA%8C%E8%AF%81%E6%9C%89%E6%95%88%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在爬取网站数据的时候，一些网站会对用户的访问频率进行限制，如果爬取过快会被封ip，而使用代理可防止被封禁。本项目使用scrapy框架对<a href="http://www.xicidaili.com/" target="_blank" rel="noopener">西刺网站</a>进行爬取，并验证爬取代理的有效性，最终将有效的代理输出并存储到json文件中。</p><p>Github地址: <a href="https://github.com/RunningGump/crawl_xiciproxy" target="_blank" rel="noopener">https://github.com/RunningGump/crawl_xiciproxy</a></p><h1 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h1><ol><li>python3.6</li><li>Scrapy 1.5.0</li></ol><h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><p>首先，我们需要创建一个Scrapy项目，在shell中使用<code>scrapy startproject</code>命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy startproject xiciproxy</span><br><span class="line">New Scrapy project <span class="string">'xiciproxy'</span>, using template directory <span class="string">'/usr/local/lib/python3.6/dist-packages/scrapy/templates/project'</span>, created <span class="keyword">in</span>:</span><br><span class="line">    /home/geng/xiciproxy</span><br><span class="line"></span><br><span class="line">You can start your first spider with:</span><br><span class="line">    <span class="built_in">cd</span> xiciproxy</span><br><span class="line">    scrapy genspider example example.com</span><br></pre></td></tr></table></figure><p>创建好一个名为<code>xiciproject</code>的项目后，接下来，你进入新建的项目目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> xiciproxy</span><br></pre></td></tr></table></figure><p>然后,使用<code>scrapy genspider &lt;name&gt; &lt;domain&gt;</code>创建一个spider：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy genspider xici xicidaili.com</span><br><span class="line">Created spider <span class="string">'xici'</span> using template <span class="string">'basic'</span> <span class="keyword">in</span> module:</span><br><span class="line">  xiciproxy.spiders.xici</span><br></pre></td></tr></table></figure><p>此时，你通过<code>cd ..</code>返回上级目录，使用<code>tree</code>命令查看项目目录下的文件，显示如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ..</span><br><span class="line">$ tree xiciproxy</span><br><span class="line">xiciproxy</span><br><span class="line">├── scrapy.cfg</span><br><span class="line">└── xiciproxy</span><br><span class="line">    ├── __init__.py</span><br><span class="line">    ├── items.py</span><br><span class="line">    ├── middlewares.py</span><br><span class="line">    ├── pipelines.py</span><br><span class="line">    ├── __pycache__</span><br><span class="line">    │   ├── __init__.cpython-36.pyc</span><br><span class="line">    │   └── settings.cpython-36.pyc</span><br><span class="line">    ├── settings.py</span><br><span class="line">    └── spiders</span><br><span class="line">        ├── __init__.py</span><br><span class="line">        ├── __pycache__</span><br><span class="line">        │   └── __init__.cpython-36.pyc</span><br><span class="line">        └── xici.py</span><br><span class="line"></span><br><span class="line">4 directories, 11 files</span><br></pre></td></tr></table></figure><p>到此为止，我们的项目就创建成功了。</p><h1 id="分析页面"><a href="#分析页面" class="headerlink" title="分析页面"></a>分析页面</h1><p>编写爬虫程序之间，首先需要对待爬取的页面进行分析，主流的浏览器中都带有分析页面的工具或插件，这里我们选用Chrome浏览器的开发者工具分析页面。</p><h2 id="链接信息"><a href="#链接信息" class="headerlink" title="链接信息"></a>链接信息</h2><p>在Chrome浏览器中打开页面<a href="http://www.xicidaili.com/" target="_blank" rel="noopener">http://www.xicidaili.com/</a>, 通过点击<code>国内高匿代理</code>和<code>国内普通代理</code>以及进行翻页操作，会发现以下规律：</p><p><code>http://www.xicidaili.com/参数1/参数2</code></p><p>参数1中<code>nn</code>代表高匿代理，<code>nt</code>代表普通代理；参数2中1,2,3,4…代表页数。</p><h2 id="数据信息"><a href="#数据信息" class="headerlink" title="数据信息"></a>数据信息</h2><p>爬取网页信息时一般使用高匿代理，高匿代理不改变客户机的请求，这样在服务器看来就像有个真正的客户浏览器在访问它，这时客户的真是IP是隐藏的，不会认为我们使用了代理。</p><p>本部分以爬取高匿代理为例子来分析如何爬取网页的数据信息。在Chrome浏览器中打开页面<a href="http://www.xicidaili.com/nn" target="_blank" rel="noopener">http://www.xicidaili.com/nn</a>, 并按<code>F12</code>键来打开开发者工具，点击Elements（元素）来查看其HTML代码，会发现每一条代理的信息都包裹在一个<code>tr</code>标签下，如下图所示：</p><p><img src="/2018/08/02/基于scrapy框架爬取西刺代理并验证有效性/xici1.png" alt="一个tr标签对应一条代理信息"></p><p>再来单独对一个<code>tr</code>标签进行分析：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tr</span> <span class="attr">class</span>=<span class="string">"odd"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"country"</span>&gt;</span><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"http://fs.xicidaili.com/images/flag/cn.png"</span> <span class="attr">alt</span>=<span class="string">"Cn"</span>&gt;</span><span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span>115.198.35.213<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span>6666<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/2018-07-20/zhejiang"</span>&gt;</span>浙江杭州<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"country"</span>&gt;</span>高匿<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span>HTTPS<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"country"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">title</span>=<span class="string">"0.144秒"</span> <span class="attr">class</span>=<span class="string">"bar"</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"bar_inner fast"</span> <span class="attr">style</span>=<span class="string">"width:85%"</span>&gt;</span></span><br><span class="line">            </span><br><span class="line">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span> <span class="attr">class</span>=<span class="string">"country"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">title</span>=<span class="string">"0.028秒"</span> <span class="attr">class</span>=<span class="string">"bar"</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"bar_inner fast"</span> <span class="attr">style</span>=<span class="string">"width:96%"</span>&gt;</span></span><br><span class="line">            </span><br><span class="line">          <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      </span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span>15天<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">td</span>&gt;</span>18-08-04 15:33<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br></pre></td></tr></table></figure><p>会发现：IP地址包裹在<code>td[2]</code>标签下，端口port包裹在<code>td[3]</code>标签下，类型（http/https）包裹在<code>td[6]</code>标签下。</p><h1 id="程序编写"><a href="#程序编写" class="headerlink" title="程序编写"></a>程序编写</h1><p>分析完页面后，接下来编写爬虫。本项目主要是对<code>xici.py</code>进行编写，对<code>settings.py</code>仅做了轻微改动。</p><h2 id="实现spider"><a href="#实现spider" class="headerlink" title="实现spider"></a>实现spider</h2><p>即编写<code>xici.py</code>文件，程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">scrapy crawl xici -o out.json -a num_pages=50 -a typ=nn</span></span><br><span class="line"><span class="string">其中`out.json`是输出有效代理的json文件，`num_pages`是爬取页数，`typ`表示代理类型，`nn`是高匿代理，`nt`是普通代理。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XiCiSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    <span class="comment"># 每一个爬虫的唯一标识</span></span><br><span class="line">    name = <span class="string">'xici'</span></span><br><span class="line">    <span class="comment"># 使用-a选项,可以将命令行参数传递给spider的__init__方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_pages=<span class="number">5</span>, typ=<span class="string">'nn'</span>, *args, **kwargs)</span>:</span></span><br><span class="line">        num_pages = int(num_pages)</span><br><span class="line">        self.num_pages = num_pages</span><br><span class="line">        self.typ = typ</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 定义起始爬取点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span> </span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, self.num_pages + <span class="number">1</span>):</span><br><span class="line">            url = <span class="string">'http://www.xicidaili.com/&#123;&#125;/&#123;&#125;'</span>.format(self.typ, page)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析response返回的网页</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        proxy_list = response.xpath(<span class="string">'//table[@id = "ip_list"]/tr[position()&gt;1]'</span>)  </span><br><span class="line">        <span class="keyword">for</span> tr <span class="keyword">in</span> proxy_list:</span><br><span class="line">            <span class="comment"># 提取代理的 ip, port, scheme(http or https)</span></span><br><span class="line">            ip = tr.xpath(<span class="string">'td[2]/text()'</span>).extract_first()</span><br><span class="line">            port = tr.xpath(<span class="string">'td[3]/text()'</span>).extract_first()</span><br><span class="line">            scheme = tr.xpath(<span class="string">'td[6]/text()'</span>).extract_first()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 使用爬取到的代理再次发送请求到http(s)://httpbin.org/ip, 验证代理是否可用</span></span><br><span class="line">            url = <span class="string">'%s://httpbin.org/ip'</span> % scheme</span><br><span class="line">            proxy = <span class="string">'%s://%s:%s'</span> % (scheme, ip, port)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            meta = &#123;</span><br><span class="line">                <span class="string">'proxy'</span>: proxy,</span><br><span class="line">                <span class="string">'dont_retry'</span>: <span class="keyword">True</span>,</span><br><span class="line">                <span class="string">'download_timeout'</span>: <span class="number">5</span>,</span><br><span class="line">                <span class="comment"># 下面的ip字段是传递给check_available方法的信息,方便检测是否可隐藏ip</span></span><br><span class="line">                <span class="string">'_proxy_ip'</span>:ip,</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url, callback=self.check_available, meta=meta, dont_filter=<span class="keyword">True</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">check_available</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        proxy_ip = response.meta[<span class="string">'_proxy_ip'</span>]</span><br><span class="line">        <span class="comment"># 判断代理是否具有隐藏IP功能</span></span><br><span class="line">        <span class="keyword">if</span> proxy_ip == json.loads(response.text)[<span class="string">'origin'</span>]:</span><br><span class="line">            <span class="keyword">yield</span>&#123;</span><br><span class="line">                <span class="string">'proxy'</span>: response.meta[<span class="string">'proxy'</span>]</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><ul><li>更改USER_AGENT：西刺代理网站会通过识别请求中的user-agent来判断这次请求是真实用户所为还是机器所为。</li><li>不遵守robots协议：网站会通过robots协议告诉搜索引擎那些页面可以抓取，哪些不可以抓取，而robots协议大多不允许抓取有价值的信息，所以咱们不遵守。</li><li>禁用cookies：如果用不到cookies，就不要让服务器知道你的cookies。</li></ul><p>文件<code>settings.py</code>中的改动如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">USER_AGENT = &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36&quot;</span><br><span class="line">ROBOTSTXT_OBEY = True</span><br><span class="line">COOKIES_ENABLED = False</span><br></pre></td></tr></table></figure><p>在编写好<code>xici.py</code>和<code>settings.py</code>后，我们的项目就大功告成啦！</p><h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>使用方法就是在命令行中执行以下命令即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy crawl xici -o out.json -a num_pages=10 -a typ=nn</span><br></pre></td></tr></table></figure><p>其中<code>out.json</code>是最终输出有效代理的json文件，<code>num_pages</code>是爬取页数，<code>typ</code>表示要爬取的代理类型，<code>nn</code>是高匿代理，<code>nt</code>是普通代理。</p><blockquote><p><strong>提示</strong> ：程序在验证代理有效性的过程中，对于无效的代理会抛出超时异常，不要管这些异常，让程序继续执行直到结束。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> python3网络爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> 西刺代理 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
